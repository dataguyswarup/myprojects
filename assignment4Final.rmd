---
title: "Elections Result : Exploratory,Win and Voteshare prediction"
author: "Swarup Kumar"
date: "6/27/2019"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

```{r echo=FALSE}
library(rpart)
library(rpart.plot)
library(rattle)
library(rJava)
library(xlsx)
library(caret)
library(knitr)
library(dplyr)
library(fastDummies)
library(RColorBrewer)
library(InformationValue)
library(reshape)
library(nnet)
library(data.table)
library(scales)
library(ROCR) 
library(ineq)
library(RWeka)
library(neuralnet)
library(car)
library(randomForest)
library(party)
library(ipred)
library(tidyr)
library(readr)
library(ggplot2)
library(gridExtra)
library(reshape2)
library(purrr)
library(corrplot)
library(corrgram)
library(psych)
library(RSNNS)
library(neuralnet)
library(RecordLinkage)
library(pscl)
library(lmtest)
library(naivebayes)
```

```{r}
#Load data for 2017 UP assembly polls
incumup2017 <- read.xlsx("LA2017_1.xlsx",sheetName = "Candidate",header = TRUE)
str(incumup2017)
#Load data for 2012 UP assembly polls
up2012 <- read.xlsx("AE2012_8913.xlsx",sheetName = "Candidate",header = TRUE)
str(up2012)
#Pick only Constituency name, Party abbrievation and Won variable from both data frames
idf1 <- data.frame(incumup2017$AC_NO,incumup2017$AC_NAME,incumup2017$PARTYABBRE,incumup2017$Won)
idf2 <- data.frame(up2012$AC_NO,up2012$AC_NAME,up2012$PARTYABBRE,up2012$Won)

#Filter bpth data frames where they Won in 2012,2017
idf11 <- idf1 %>% filter(incumup2017.Won==1)
idf21 <- idf2 %>% filter(up2012.Won==1)
#Merge the dataframe based on Constituency name
merdf <- merge(idf11,idf21,by.x = "incumup2017.AC_NO",by.y = "up2012.AC_NO")
str(merdf)


#Check if we are comparing the same Political party
levenScore <- levenshteinSim(tolower(as.character(merdf$incumup2017.PARTYABBRE)),tolower(as.character(merdf$up2012.PARTYABBREABBRE)))


#Function to calculate Incumbency (Pro -> 0 and Anti -> -1)
incumFn <- function(x)
{
  incumbVec <- c()
for(i in 1:nrow(x))
{  
 if(i ==1)
  {
    incumbElem <- 0
     
  }
  else
  {
    incumbElem <- -1
  }
 incumbVec <- c(incumbVec,incumbElem)
}
  return(incumbVec)
}
#Call the function by passing the vector of levenstheimSim distance between party abbreviations
#incumbDf <- incumFn(levenScore)
#Append the output frame to merdf as an additional column
#merdf <- cbind(merdf,incumbDf)

#Plot the barplot showing how much of Pro/Anti Incumbency against the political parties
#ggplot(data=merdf)+geom_bar(aes(x=up2012.PARTYABBRE,fill=as.factor(incumbDf)),show.legend = #FALSE)+ggtitle(label="Incumbency")+theme_bw()+xlab("Parties")+ylab("Number of seats Lost (Red)")
```

```{r}
#Exploratory model : factors contributing to Win followed by Prediction model
#Remove ST_CODE,ST_NAME,MONTH,YEAR,AC_NO,AC_TYPE,Helper1,Party1 for further analysis as these are not of importance

incumup2017Filtered1 <- incumup2017[,c(-1,-2,-3,-4,-8,-16,-21)]

#Formating Total.Assets,Liabilities,Age
#Format Rs in the assets, Liabilities column; During the vlookup ~ Rs 3 crore+ kind of automatically removed

#str(incumup2017Filtered1)
#Substitue FALSE,Nil with 0 and Rs & , with blank
incumup2017Filtered1[,14] <- gsub("FALSE",0,incumup2017Filtered1[,14])
incumup2017Filtered1[,14] <- gsub("Nil",0,incumup2017Filtered1[,14])
incumup2017Filtered1[,14] <- gsub("Rs","",incumup2017Filtered1[,14])
incumup2017Filtered1[,14] <- gsub(",","",incumup2017Filtered1[,14])


#Convert Total.Assets to numeric type
incumup2017Filtered1[,14] <- parse_number(incumup2017Filtered1[,14])

#Format Rs in the assets, Liabilities column; During the vlookup ~ Rs 3 crore+ kind of automatically removed
#Substitue FALSE,Nil with 0 and Rs & , with blank
incumup2017Filtered1[,13] <- gsub("FALSE",0,incumup2017Filtered1[,13])
incumup2017Filtered1[,13] <- gsub("Nil",0,incumup2017Filtered1[,13])
incumup2017Filtered1[,13] <- gsub("Rs","",incumup2017Filtered1[,13])
incumup2017Filtered1[,13] <- gsub(",","",incumup2017Filtered1[,13])
#Convert Liabilities to numeric type
incumup2017Filtered1[,13] <- parse_number(incumup2017Filtered1[,13])

#Age as Numeric variables
#Replace 0 for all NULL values i.e. for NOTA option
incumup2017Filtered1[,7] <- gsub("NULL",0,incumup2017Filtered1[,7])
#Convert Liabilities to numeric type
incumup2017Filtered1[,7] <- parse_number(incumup2017Filtered1[,7])

#Education,Sex,CAND_CATEGORY are categorical variables ; convert them into dummy variables

#Transform for Education Categories as Under Graduate -> 12th and below pass, Graduate,Post Graduate,Doctorate
#All not given data will be marked Ignored because if we remove them, then analysis data will be reduced
incumup2017Filtered1[,12] <- as.factor(gsub("FALSE","Ignored",incumup2017Filtered1[,12]))
incumup2017Filtered1[,12] <- as.factor(gsub("Others","Ignored",incumup2017Filtered1[,12]))
incumup2017Filtered1[,12] <- as.factor(gsub("Not Given","Ignored",incumup2017Filtered1[,12]))

incumup2017Filtered1[,12] <- as.factor(gsub("10th Pass","Under Graduate",incumup2017Filtered1[,12]))
incumup2017Filtered1[,12] <- as.factor(gsub("8th Pass","Under Graduate",incumup2017Filtered1[,12]))
incumup2017Filtered1[,12] <- as.factor(gsub("5th Pass","Under Graduate",incumup2017Filtered1[,12]))
incumup2017Filtered1[,12] <- as.factor(gsub("12th Pass","Under Graduate",incumup2017Filtered1[,12]))

#Replace NULL with NA to ignore NOTA option for CAND_SEX variable
incumup2017Filtered1[,5] <- as.factor(gsub("NULL",NA,incumup2017Filtered1[,5]))
incumup2017Filtered1[,5] <- as.factor(gsub("O",NA,incumup2017Filtered1[,5]))

#Remove all NA rows for exploratory analysis, exclude NOTA and reassign it to new variable for exploratory analysis
incumup2017Filtered <- na.omit(incumup2017Filtered1)
#Create netasset variable and append that to main dataframe
netasset <- incumup2017Filtered$Total.Assets - incumup2017Filtered$Liabilities
incumup2017Filtered <- cbind(incumup2017Filtered,netasset)

#Filter for only top political parties
partyabbre <- filter(incumup2017Filtered,PARTYABBRE %in% c("BJP","INC","SP","BSP","RLD","ADAL"))
#Make Age categories only for exploratory analysis
CutAge <- cut(partyabbre$CAND_AGE,breaks=c(0,25,35,50,65,Inf),labels=c("25","25to35","35to50","50to65",">65"))
#Make netasset categories only for exploratory analysis
CutnetAsset <- cut(partyabbre$netasset,breaks=c(-Inf,0,1000000,2500000,5000000,10000000,Inf),labels=c("Negative","Upto10L","10Lto25L","25Lto50L","50Lto1CR",">1CR"))

#Exploraotry Analysis based on Wins (Won variable of the dataset where Won==1)

wonfilter <- filter(incumup2017Filtered,Won==1)
#Make Age categories only for exploratory analysis
CutAgeW <- cut(wonfilter$CAND_AGE,breaks=c(0,25,35,50,65,Inf),labels=c("25","25to35","35to50","50to65",">65"))
#Make netasset categories only for exploratory analysis
CutnetAssetW <- cut(wonfilter$netasset,breaks=c(-Inf,0,1000000,2500000,5000000,10000000,Inf),labels=c("Negative","Upto10L","10Lto25L","25Lto50L","50Lto1CR",">1CR"))
#How many Male / Female candidates Won
wonfilter %>% group_by(CAND_SEX) %>% summarise(win=sum(Won)) %>%
  ggplot(aes(x = CAND_SEX, y = win, fill = CAND_SEX)) +
    geom_bar(stat = "identity",show.legend = FALSE) +
    theme_bw() +
    labs(
        x = "M/F",
        y = "No of candidates",
        title = paste(
            "Won vs Gender "
        )
    )
#What Age groups had most winnables?
  ggplot(data=wonfilter)+
   geom_bar(aes(x=CutAgeW,fill=as.factor(Won)),show.legend = FALSE)+
   ggtitle(label="Age group of Winnables  ")+
   theme_bw()+labs(
         x = "Age Range",
         y = "No of candidates Won",
         title = paste(
             "What Age groups had most winnables? "
         ))
 #+geom_text(aes(label=CutnetAssetW),vjust=0.2,colour="black",size=5)
#Partywise seat won
partyabbre %>% group_by(PARTYABBRE) %>% summarise(sum_votes=sum(Won)) %>%
  ggplot(aes(x = PARTYABBRE, y = sum_votes, fill = PARTYABBRE)) +
    geom_bar(stat = "identity",show.legend = FALSE)+ 
    theme_bw() +
    labs(
        x = "Parties",
        y = "No of seats Won",
        title = paste(
            "Partywise seat tally - 2017 UPAssembly"
        )
    )
CutnetAssetF <- cut(incumup2017Filtered$netasset,breaks=c(-Inf,0,1000000,2500000,5000000,10000000,Inf),labels=c("Negative","Upto10L","10Lto25L","25Lto50L","50Lto1CR",">1CR"))
#NetAsset among M/F
ggplot(data=incumup2017Filtered)+geom_bar(aes(x=CutnetAssetF,fill=as.factor(CAND_SEX)))+theme_bw()+labs(
        x = "NetAsset",
        y = "No of candidates",
        title = paste(
            "Net assets among M/F candidates"
        ))
#Netasset among Age groups
CutAgeF <- cut(incumup2017Filtered$CAND_AGE,breaks=c(0,25,35,50,65,Inf),labels=c("25","25to35","35to50","50to65",">65"))
ggplot(data=incumup2017Filtered)+geom_bar(aes(x=CutAgeF,fill=as.factor(CutnetAssetF)))+theme_bw()+labs(
        x = "Age",
        y = "Nof of candidates",
        title = paste(
            "Wealth among Age groups of Candidates"
        ))
#Partywise (among top 6) M/F
ggplot(data=partyabbre)+geom_bar(aes(x=PARTYABBRE,fill=as.factor(CAND_SEX)))+theme_bw()+labs(
        x = "Political Parties",
        y = "Nof of candidates",
        title = paste(
            "Distribution of Party tickets among M/F"
        ))
#Partywise netasset details
ggplot(data=partyabbre)+geom_bar(aes(x=PARTYABBRE,fill=as.factor(CutnetAsset)))+theme_bw()+labs(
        x = "Political Parties",
        y = "Nof of candidates",
        title = paste(
            "Net Assets of Candidates in Parties"
        ))
#Partywise Votes garnered
partyabbre %>% group_by(PARTYABBRE) %>% summarise(sum_votes=sum(TOTALVALIDVOTESPOLLED)) %>%
  ggplot(aes(x = PARTYABBRE, y = sum_votes, fill = PARTYABBRE)) +
    geom_bar(stat = "identity") +
    theme_bw() +
    labs(
        x = "Parties",
        y = "Votes Polled",
        title = paste(
            "Votes polled Vs Political Parties "
        )
    )
#Partywise ticket distribution Vs Age
ggplot(data=partyabbre)+geom_bar(aes(x=CutAge,fill=as.factor(PARTYABBRE)))+theme_bw()+labs(
        x = "Age Range",
        y = "No of candidates",
        title = paste(
            "Age of Candidates Vs Political Parties "
        ))
#Partywise Criminal cases of Candidates
partyabbre %>% group_by(PARTYABBRE) %>% summarise(sum_votes=sum(Criminal.Case)) %>%
  ggplot(aes(x = PARTYABBRE, y = sum_votes, fill = PARTYABBRE)) +
    geom_bar(stat = "identity") +
    theme_bw() +
    labs(
        x = "Parties",
        y = "Criminal Cases",
        title = paste(
            "Criminals in Political Parties "
        )
    )
#Partywise Criminal cases Vs Age
partyabbre %>% group_by(CAND_AGE) %>% summarise(sum_votes=sum(Criminal.Case)) %>%
  ggplot(aes(x = CAND_AGE, y = sum_votes, fill = CAND_AGE)) +
    geom_bar(stat = "identity") +
    theme_bw() +
    labs(
        x = "Candidate Age",
        y = "Criminal Cases",
        title = paste(
            "Age of candidates having Criminal Records"
        )
    )
#Partywise Candidate categories
ggplot(data=partyabbre)+geom_bar(aes(x=PARTYABBRE,fill=CAND_CATEGORY))+theme_bw()+labs(
        x = "Parties",
        y = "No of candidates",
        title = paste(
            "Candidate Categories Vs Political Parties"
        ))
#Education level in Parties
ggplot(data=partyabbre)+geom_bar(aes(x=PARTYABBRE,fill=as.factor(Education)))+theme_bw()+labs(
        x = "Education Level",
        y = "No of candidates",
        title = paste(
            "Education Level in Political Parties "
        ))
#Education level among Age Groups
ggplot(data=partyabbre)+geom_bar(aes(x=CutAge,fill=as.factor(Education)))+theme_bw()+labs(
        x = "Education Level",
        y = "No of candidates",
        title = paste(
            "Education Level vs Age Group "
        ))
#Education level among M/F
ggplot(data=partyabbre)+geom_bar(aes(x=CAND_SEX,fill=as.factor(Education)))+theme_bw()+labs(
        x = "Education Level",
        y = "No of candidates",
        title = paste(
            "Education Level Vs Gender"
        ))
# #Check for outliers using Boxplot for numeric variables
# boxplot(incumup2017Filtered$CAND_AGE~incumup2017Filtered$POSITION)
# boxplot(incumup2017Filtered$Total.Assets~incumup2017Filtered$POSITION)
# boxplot(partyabbre$netasset~partyabbre$POSITION)

# #Overall Education levels of all Candidates across party lines
# plot(incumup2017Filtered$Education)
# #Category of Candidates across party lines
# #plot(incumup2017Filtered$CAND_CATEGORY)
# plot(incumup2017Filtered$CAND_SEX)

#Data transformation to proceed for Prediction Model
#Create dummy variable for Categorical Variables Gender,Category,Education
dmy<- dummy_cols(incumup2017Filtered, select_columns = c("CAND_SEX","CAND_CATEGORY","Education"))
#Check the structure of dataset after applying dummy variables
str(dmy)
#Remove the factor variables except target variable, Won
trsfm<- dmy[,c(-4,-5,-6,-10,-12,-13,-14)]
#Convert Won variable to factorial or else models won't run
trsfm[,8] <- as.factor(trsfm[,8])

#Running corrplot on all numeric variables
corrplot(cor(trsfm[,c(-1,-3,-5,-8)]), method = "circle")
# Check for data consistency using KMO
KMO(trsfm[,c(-1,-3,-5,-8)])

#Won is the target variable or to be predicted, Party with Position 1 is 1 or else 0

#Model to be Won~distname,acname,candname,age,sex,partyabbr,criminalcase,education,assets,liabilities,Totalvalidvotespolled - Position
```
#C45 Technique
```{r}
#Creating data partition for train,test and Holdout
set.seed(12345)

#Split the dataset into train, test and holdout (65%,15%,20%) 

sampleR <- sample.int(n = nrow(trsfm), size = floor(.65*nrow(trsfm)), replace = F)
sampleR1 <- sample.int(n = nrow(trsfm), size = floor(.15*nrow(trsfm)), replace = F)
sampleR2 <- sample.int(n = nrow(trsfm), size = floor(0.2*nrow(trsfm)), replace = F)

trainC45 <- trsfm[sampleR, ]
testC45  <- trsfm[sampleR1,]
holdoutC45 <- trsfm[sampleR2,]

#Fit the model
fitTrainRWeka <- J48(Won~., data=trainC45)

# summarize the fit
summary(fitTrainRWeka)
# make predictions

predictionsTestRWeka <- predict(fitTrainRWeka, testC45)
predictionsholdRWeka <- predict(fitTrainRWeka, holdoutC45)


caret::confusionMatrix(predictionsTestRWeka,testC45$Won,positive="1",mode="everything")
caret::confusionMatrix(predictionsholdRWeka,holdoutC45$Won,positive="1",mode="everything")

ks_plot(testC45$Won,predictionsTestRWeka)
InformationValue::plotROC(testC45$Won,c(as.numeric(predictionsTestRWeka)))
InformationValue::plotROC(holdoutC45$Won,c(as.numeric(predictionsholdRWeka)))
```

#CART Technique with Scaling(Bagging)
```{r}
#Creating data partition for train,test and Holdout
set.seed(1234)
sampleR <- sample.int(n = nrow(trsfm), size = floor(.65*nrow(trsfm)), replace = F)
sampleR1 <- sample.int(n = nrow(trsfm), size = floor(.15*nrow(trsfm)), replace = F)
sampleR2 <- sample.int(n = nrow(trsfm), size = floor(0.2*nrow(trsfm)), replace = F)

trainRB <- trsfm[sampleR, ]
testRB  <- trsfm[sampleR1,]
holdoutRB <- trsfm[sampleR2,]
# fit model
fitRB <- bagging(Won~., data=trainRB)

# make predictions
predictions <- predict(fitRB,testRB, type="class")
predictionsH <- predict(fitRB,holdoutRB, type="class")
# summarize accuracy


caret::confusionMatrix(predictions,testRB$Won, positive="1", mode="everything")
caret::confusionMatrix(predictionsH,holdoutRB$Won, positive="1", mode="everything")

ks_plot(predictions,testRB$Won)
ks_plot(predictionsH,holdoutRB$Won)

InformationValue::plotROC(testRB$Won,c(as.numeric(predictions)))
InformationValue::plotROC(holdoutRB$Won,c(as.numeric(predictionsH)))
```
# RandomForest
```{r}
#Creating data partition for train,test and Holdout
set.seed(134567)
trsfm1<-trsfm[,c(-1,-3,-5)]
sampleR <- sample.int(n = nrow(trsfm1), size = floor(.65*nrow(trsfm1)), replace = F)
sampleR1 <- sample.int(n = nrow(trsfm1), size = floor(.15*nrow(trsfm1)), replace = F)
sampleR2 <- sample.int(n = nrow(trsfm1), size = floor(0.2*nrow(trsfm1)), replace = F)

trainRand <- trsfm1[sampleR, ]
testRand  <- trsfm1[sampleR1,]
holdoutRand <- trsfm1[sampleR2,]

#To avoid Error in eval(predvars,data,env) from running model fitment
names(trainRand) <- make.names(names(trainRand))
names(testRand) <- make.names(names(testRand))
names(holdoutRand) <- make.names(names(holdoutRand))
# fit model
#mtry is SQRT(P) = SQRT(19)=
trainrandomfit <- randomForest(Won~., data=trainRand,
                importance=TRUE,ntree=200,mtry=8)

print(trainrandomfit)
# summarize the fit
summary(trainrandomfit)

#Plot to to check for optimal number of Tree value
plot(trainrandomfit)
legend("topright", c("OOB", "0", "1"), text.col=1:6, lty=1:3, col=1:3) 
title(main="Error Rates Random Forest for Won Training data")

impVar <- round(randomForest::importance(trainrandomfit), 2) 

impVar[order(impVar[,1], decreasing=TRUE),] 

#Plot the important variables that influence prediction
varImpPlot(trainrandomfit,n.var = min(10,nrow(trainrandomfit$importance)),scale = TRUE,main="Top 10 Variable of importance",sort=TRUE)

#Which variables are used the most in prediction, CAND_CATEGORY_SC,Education_Illiterate are the least used
varUsed(trainrandomfit)

caret::varImp(trainrandomfit)

# make predictions
#predictions <- predict(fit, trainR)
#predictionsRTrain <- predict(trainrandomfit, testR)
predictionsRTest <- predict(trainrandomfit, testRand)
predictionsRHoldout <- predict(trainrandomfit, holdoutRand)
# summarize accuracy

#table(predictionsRTest, testRand$Won)

cforest(Won ~ ., data=trainRand, controls=cforest_control(mtry=2, mincriterion=0))
cforest(Won ~ ., data=testRand, controls=cforest_control(mtry=2, mincriterion=0))
#cforest(Won ~ ., data=holdoutRand, controls=cforest_control(mtry=2, mincriterion=0))

x <- ctree(Won ~ ., data=trainRand)
x1 <- ctree(Won ~ ., data=testRand)
#x2 <- ctree(Won~.,data = holdoutRand)
plot(x, type="simple")
plot(x1, type="simple")

#plot(x2, type="simple")

caret::confusionMatrix(predictionsRTest,testRand$Won,positive="1",mode="everything")

caret::confusionMatrix(predictionsRHoldout,holdoutRand$Won,positive="1",mode="everything")

ks_plot(testRand$Won,predictionsRTest)
ks_plot(holdoutRand$Won,predictionsRHoldout)

InformationValue::plotROC(testRand$Won,c(as.numeric(predictionsRTest)))
InformationValue::plotROC(holdoutRand$Won,c(as.numeric(predictionsRHoldout)))
#Tuning is not done since even on test data the accuracy is high ~ 98%
t <-tuneRF(trainRand[,-5],trainRand[,5],
           stepFactor = 0.5,
           plot=TRUE,
           ntreeTry = 100,
           trace = TRUE,
           improve = 0.05)
#This mtry of 8 and ntree of 200 is fed back to original model
#Histogram to identify the number of nodes for the model
hist(treesize(trainrandomfit),main="No of nodes for the Trees",col="green")
```
# Logistic Regression
```{r}
#Create partition of data into train,test and holdout
set.seed(1234)
trsfm1<-trsfm[,c(-1,-3,-5)]
sampleR <- sample.int(n = nrow(trsfm1), size = floor(.65*nrow(trsfm1)), replace = F)
sampleR1 <- sample.int(n = nrow(trsfm1), size = floor(.15*nrow(trsfm1)), replace = F)
sampleR2 <- sample.int(n = nrow(trsfm1), size = floor(0.2*nrow(trsfm1)), replace = F)

trainL <- trsfm1[sampleR, ]
testL  <- trsfm1[sampleR1,]
holdoutL <- trsfm1[sampleR2,]

#Running Logistic regression on the traindata set
logitmod <- glm(Won ~ ., family = "binomial", data=trainL)

#Summarize the model
summary(logitmod)

lrtest(logitmod)
#Mc faddens rsquared > 10% is good model or else model is not good
pR2(logitmod)

#Predict the test data based on the above logistic model
pred <- predict(logitmod, newdata = testL, type = "response")
predH <- predict(logitmod, newdata = holdoutL, type = "response")

#Create confusion matrix table Test
y_pred_num<- ifelse(pred > 0.5, 1, 0)
y_pred <- factor(y_pred_num, levels=c(0, 1))
y_act <- testL$Won
#table(y_pred,y_act)


#Create confusion matrix table Holdout
y_pred_numH<- ifelse(predH > 0.5, 1, 0)
y_predH <- factor(y_pred_numH, levels=c(0, 1))
y_actH <- holdoutL$Won
#table(y_predH,y_actH)
#Create confusion matrix table from caret package
caret::confusionMatrix(y_pred,y_act, positive="1", mode="everything")
caret::confusionMatrix(y_predH,y_actH, positive="1", mode="everything")

ks_plot(y_act,y_pred)

ks_plot(y_actH,y_predH)
#Plot ROC curve
InformationValue::plotROC(y_act, pred)

InformationValue::plotROC(y_actH, predH)

```
#Naive Bayes
```{r}
#Naive Bayes method for prediction
set.seed(1234)

sampleR <- sample.int(n = nrow(trsfm), size = floor(.65*nrow(trsfm)), replace = F)
sampleR1 <- sample.int(n = nrow(trsfm), size = floor(.15*nrow(trsfm)), replace = F)
sampleR2 <- sample.int(n = nrow(trsfm), size = floor(0.2*nrow(trsfm)), replace = F)

trainN <- trsfm[sampleR, ]
testN  <- trsfm[sampleR1,]
holdoutN <- trsfm[sampleR2,]

nbModel <- naive_bayes(Won~.,trainN,usekernel = TRUE)
summary(nbModel)


# predvec <- ifelse(pred=="Lost", 1, 0)
# realvec <- ifelse(realResults=="Lost", 1, 0)

plot(nbModel)
nbPredict <- predict(nbModel,testN,type="prob")

nbPredictH <- predict(nbModel,holdoutN,type="prob")

#Running prediction on test
p1 <- predict(nbModel,testN)
(tab1 <- table(p1,testN$Won))
#Type 2 (miss classification)
1 -sum(diag(tab1))/sum(tab1)
#Running prediction on holdout
p2 <- predict(nbModel,holdoutN)
(tab2 <- table(p2,holdoutN$Won))
#Type 2 (miss classification)
1 -sum(diag(tab2))/sum(tab2)

#caret::confusionMatrix(nbPredict,testN$Won,positive="1",mode="everything")
ks_plot(testN$Won,as.numeric(nbPredict))
#InformationValue::plotROC(testN$Won,c(as.numeric(nbPredict)))
```
#Linear Regression for Voteshare
```{r}
#Linear regression model for predicting vote share
#Load Electors sheet from LA_2017 sheet for Total Electors, Total Votes polled or %, AC_N0
#Merge parties, votespolled, total electors based on AC_NO and then analyze %
#Build a regression model to predict vote share

incumup2017El <- read.xlsx("C:/BigData/BABI/Assignment4/LA2017_1.xlsx",sheetName = "Electors",header = TRUE)

incumup2017El <- incumup2017El[,c(-1,-2,-5,-6)]

#Merge dataframe based on Constituency name
merdfVote <- merge(incumup2017El,incumup2017Filtered,by.x = "AC_NAME",by.y = "AC_NAME")
#Calculate Voteshare
voteShare <- (merdfVote$TOTALVALIDVOTESPOLLED / merdfVote$TOTAL.VOTES.POLLED)*100
#Add it back to original data frame
merdfVote <- cbind(merdfVote,voteShare)
#View(merdfVote)

#First remove too big factorial variables namely AC_NAME,TOTAL.VOTES.POLLED,TotalElectors,DIST_NAME,AC_NO.y,TOTALVALIDVOTESPOLLED,Won
merdfVote <- merdfVote[,c(-1,-2,-3,-6,-8,-13,-14,-19,-18,-17)]

#Filter for parties of relevance to calculate voteshare
partyabbre1 <- filter(merdfVote,PARTYABBRE %in% c("BJP","INC","SP","BSP","RLD","ADAL"))
partyabbre1 %>% group_by(PARTYABBRE) %>% summarise(sum_votes=sum(voteShare)/403) %>%
  ggplot(aes(x = PARTYABBRE, y = sum_votes, fill = PARTYABBRE)) +
    geom_bar(stat = "identity") +
    theme_bw() +
    labs(
        x = "Parties",
        y = "Votes Share",
        title = paste(
            "Votes Share Vs Political Parties "
        )
    )

#Fit the regression model with voteshare as the target variable
votelm <- lm(voteShare~.,data = merdfVote)
#Plot the model
plot(votelm,col="blue")

#Run predict on model
#options(max.print=100000)
summary(votelm)
#AIC Value of the model
AIC(votelm)
#Calculate cooks distance for outliers
cooksd <- cooks.distance(votelm)
sample_size <- nrow(merdfVote)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4/sample_size, col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4/sample_size, names(cooksd),""), col="blue") 

```
#Random Forest for voteshare
```{r}
set.seed(1234)
trsfmV<-merdfVote[,-7]
sampleR <- sample.int(n = nrow(trsfmV), size = floor(.65*nrow(trsfmV)), replace = F)
sampleR1 <- sample.int(n = nrow(trsfmV), size = floor(.15*nrow(trsfmV)), replace = F)
sampleR2 <- sample.int(n = nrow(trsfmV), size = floor(0.2*nrow(trsfmV)), replace = F)

trainRV <- trsfmV[sampleR, ]
testRV  <- trsfmV[sampleR1,]
holdoutRV <- trsfmV[sampleR2,]
#mtry is p/3 i.e. 11/3~3to4 for regression
trainrandomfitv <- randomForest(voteShare~., data=trainRV,mtry=6,ntree=100,
                importance=TRUE)

print(trainrandomfitv)

#Plot the OOB Error to check for optimal trees, reduced ntree from 500 to 100
plot(trainrandomfitv)
legend("topright", c("OOB", "0", "1"), text.col=1:6, lty=1:3, col=1:3) 
title(main="Error Rates Random Forest voteshare Training data")

#Get the importance of each variable for the regression
impVarV <- round(randomForest::importance(trainrandomfitv), 2) 

impVarV[order(impVarV[,1], decreasing=TRUE),] 

#Plot to check importance of variables on model
varImpPlot(trainrandomfitv,n.var = min(10,nrow(trainrandomfitv$importance)),scale = TRUE,main="Top 10 Variable of importance",sort=TRUE)
#Print the variable importance as weights
caret::varImp(trainrandomfitv)
#Predict on the test data
predictionsRV <- predict(trainrandomfitv, newdata = testRV,type = "response")

#Put the actual and predicted values in data frame and run correlation
actual_pred <- data.frame(pred<- predictionsRV,actual<- testRV$voteShare)
plot(actual_pred$pred....predictionsRV,actual_pred$actual....testRV.voteShare,type="p",main="Actual Vs Predicted voteshare RF",xlab="Predicted",ylab="Actual",col=c("blue","red"))
sample_size <- nrow(testRV)
abline(h=4/sample_size,col="red")

rsquaredRF <- cor(actual_pred)^2 
rsquaredRF
RMSE <- sqrt(sum(predictionsRV - testRV$voteShare)^2)
RMSE
MAE(testRV$voteShare,predictionsRV)
#Another way to run random forest via cforest package
cfit <- cforest(voteShare ~ ., data=trainRV, controls=cforest_unbiased(mtry=6, ntree=100))
#Check RSquared,RMSE
cforestStats(cfit)
  #Sort the variable by decreasing importance
rev(sort(varimp(cfit)))

#Run the prediction
cpred <- predict(cfit, newdata=testRV, type="response")

#cor(cpred,testRV$voteShare)^2
actual_pred1 <- data.frame(pred<- cpred,actual<- testRV$voteShare)
plot(actual_pred1$voteShare,actual_pred1$actual....testRV.voteShare,type="p",main="Actual Vs Predicted voteshare CRF",xlab="Predicted",ylab="Actual",col=c("blue","red"))
rsquaredCRF <- cor(actual_pred1)^2
rsquaredCRF
x <- ctree(voteShare ~ ., data=trainRV)

plot(x, type="simple")
#Tuning the RF model for optimal number of mtry
t <-tuneRF(trainRV[,-10],trainRV[,10],
           stepFactor = 0.5,
           plot=TRUE,
           ntreeTry = 100,
           trace = TRUE,
           improve = 0.05)
# #Histogram to identify the number of nodes for the model
hist(treesize(trainrandomfitv),main="No of nodes for the Trees",col="green")
```
#NeuralNetwork for voteshare
```{r}
## set the seed to make your partition reproducible
set.seed(1234)
#PARTYABBRE is removed
trsfmN <- merdfVote[,-7]

#Creating dummy variables for Gender,Category,Education
dmyN<- dummy_cols(trsfmN, select_columns = c("CAND_SEX","CAND_CATEGORY","Education"))
#Remove the factorial variables
trsfmNN <-dmyN[,c(-4,-5,-8)]
indexN <- sample(nrow(trsfmNN),round(0.7*nrow(trsfmNN)))
#Split data
NN.train.data <- trsfmNN[indexN,]
NN.test.data <- trsfmNN[-indexN,]
#Format names for whitespace to .
names(NN.train.data) <- make.names(names(NN.train.data))
names(NN.test.data) <- make.names(names(NN.test.data))
#Write the formula
fml =voteShare~TotalElectors+POLL.PERCENTAGE+AC_NO.y+ CAND_AGE+ +Criminal.Case+netasset +CAND_SEX_M+CAND_SEX_F+CAND_CATEGORY_SC+ CAND_CATEGORY_GEN+CAND_CATEGORY_ST+
Education_Under.Graduate+Education_Literate+Education_Graduate+
  Education_Graduate.Professional+Education_Ignored+Education_Post.Graduate+Education_Doctorate+Education_Illiterate

#Create the neuralnet model
#linear.output = TRUE for Regression

nn2 <- neuralnet(fml, data=NN.train.data,
                         hidden=4,
                         linear.output = TRUE
                         )
summary(nn2)

plot(nn2)
#Prediction on test data
predNN <- compute(nn2,NN.test.data)
#Put it in dataframe
actual_predN <- data.frame(pred<- predNN$net.result,actual<- NN.test.data$voteShare)

plot(actual_predN$pred....predNN.net.result,actual_predN$actual....NN.test.data.voteShare,type="p",main="Actual Vs Predicted voteshare NN",xlab="Predicted",ylab="Actual",col=c("blue","red"))

MAE(NN.test.data$voteShare,predNN$net.result)

rsquaredN <- cor(actual_pred)^2
rsquaredN
RMSE <- sqrt(sum(predNN$net.result - NN.test.data$voteShare)^2)
RMSE
```

